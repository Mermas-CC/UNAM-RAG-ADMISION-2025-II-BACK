import os
from dotenv import load_dotenv
from fastapi import FastAPI, Request
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from llama_index.core import Document, VectorStoreIndex, Settings, StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore
import chromadb
from llama_index.core.node_parser import SemanticSplitterNodeParser
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.gemini import Gemini
import google.generativeai as genai
from llama_index.core.embeddings import BaseEmbedding
import google.generativeai as genai
from typing import List
from starlette.middleware.sessions import SessionMiddleware
from fastapi.middleware.cors import CORSMiddleware

# --- 0. CARGAR VARIABLES DE ENTORNO ---
load_dotenv()

class GeminiEmbedding(BaseEmbedding):
    def __init__(self, model: str = "models/embedding-001"):
        super().__init__()
        self._model = model  # usar atributo privado en lugar de `self.model`

    def _get_query_embedding(self, query: str) -> List[float]:
        result = genai.embed_content(
            model=self._model,
            content=query,
        )
        return result["embedding"]

    def _get_text_embedding(self, text: str) -> List[float]:
        result = genai.embed_content(
            model=self._model,
            content=text,
        )
        return result["embedding"]

    async def _aget_query_embedding(self, query: str) -> List[float]:
        return self._get_query_embedding(query)

if not os.getenv("GOOGLE_API_KEY"):
    print("‚ùå Error: La variable de entorno GOOGLE_API_KEY no fue encontrada.")
    exit()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    print("‚ùå Error: La variable de entorno GEMINI_API_KEY no fue encontrada.")
    exit()

# Configurar Gemini API
genai.configure(api_key=GEMINI_API_KEY)

# --- 1. CONFIGURAR MODELOS LLAMA_INDEX ---
print("‚öôÔ∏è Configurando modelos...")

Settings.llm = Gemini(model="gemini-2.5-flash", max_output_tokens=1024)
Settings.embed_model = GeminiEmbedding(model="models/embedding-001")

# --- 2. CARGAR Y PROCESAR DOCUMENTOS (SI ES NECESARIO) ---
PERSIST_DIR = "./chroma_db"

if not os.path.exists(PERSIST_DIR):
    print("üìÇ No se encontr√≥ un √≠ndice existente. Creando uno nuevo...")
    print("üìÑ Cargando y procesando documentos...")
    try:
        with open("data/REGLAMENTO_ADMISION.txt", "r", encoding="utf-8") as f1, \
             open("data/PROSPECTO_ADMISION.txt", "r", encoding="utf-8") as f2:
            texto1 = f1.read()
            texto2 = f2.read()
    except FileNotFoundError as e:
        print(f"‚ùå Error: No se encontr√≥ el archivo {e.filename}.")
        exit()

    document1 = Document(text=texto1)
    document2 = Document(text=texto2)

    splitter = SemanticSplitterNodeParser(
        buffer_size=1,
        breakpoint_percentile_threshold=95,
        embed_model=Settings.embed_model
    )
    nodes = splitter.get_nodes_from_documents([document1, document2])
    print(f"‚úÖ Documentos procesados en {len(nodes)} chunks sem√°nticos.")

    print("üß† Creando y guardando el √≠ndice vectorial...")
    db = chromadb.PersistentClient(path=PERSIST_DIR)
    chroma_collection = db.get_or_create_collection("admision_unap")
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    storage_context = StorageContext.from_defaults(vector_store=vector_store)
    index = VectorStoreIndex(nodes, storage_context=storage_context)
    print("‚úÖ √çndice vectorial creado y guardado.")
else:
    print(f"üìÇ Encontrado un √≠ndice existente en '{PERSIST_DIR}'. Carg√°ndolo...")
    db = chromadb.PersistentClient(path=PERSIST_DIR)
    chroma_collection = db.get_or_create_collection("admision_unap")
    
    # Debug: Verificar contenido de la colecci√≥n
    try:
        collection_count = chroma_collection.count()
        print(f"üîç DEBUG: Documentos en ChromaDB al cargar: {collection_count}")
        
        if collection_count > 0:
            # Intentar obtener algunos documentos para verificar
            sample_docs = chroma_collection.peek(limit=3)
            print(f"üîç DEBUG: Muestra de documentos: {len(sample_docs['ids'])} encontrados")
            if sample_docs['documents']:
                print(f"üîç DEBUG: Primer documento (primeros 100 chars): {sample_docs['documents'][0][:100]}...")
        else:
            print("‚ö†Ô∏è  WARNING: La colecci√≥n est√° vac√≠a!")
            
    except Exception as e:
        print(f"‚ùå Error verificando ChromaDB: {e}")
    
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    index = VectorStoreIndex.from_vector_store(
        vector_store,
        embed_model=Settings.embed_model
    )
    print("‚úÖ √çndice vectorial cargado.")


# --- 4. CONFIGURAR MOTOR DE CONSULTAS ---
print("üöÄ Configurando motor de consultas RAG...")
query_engine = index.as_query_engine(similarity_top_k=7)

print("‚úÖ Sistema RAG listo para consultas.")

# --- 5. FASTAPI APP ---
app = FastAPI()

# --- CONFIGURAR CORS ---
# Esto permite que el frontend de React (que se ejecutar√° en otro puerto)
# se comunique con este backend.
# Para producci√≥n, es recomendable restringir los or√≠genes.
origins = [
    "http://localhost",
    "http://localhost:3000",
    "http://localhost:5173",  # Puerto com√∫n para Vite
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.add_middleware(SessionMiddleware, secret_key=os.urandom(24))

app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

class ChatRequest(BaseModel):
    message: str
    history: List[dict]

def llamar_llm_streaming(prompt: str):
    """Llamada a Gemini streaming por google.generativeai"""
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        stream = model.generate_content(prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
    except Exception as e:
        print(f"‚ùå Error llamando a Gemini: {e}")
        yield "Error: no se pudo contactar al modelo de IA."

def generar_prompt(pregunta, contexto, historial):
    historial_texto = "\n".join(
        [f"{msg['role']}: {msg['parts'][0]}" for msg in historial]
    )
    return f"""
## ROL Y OBJETIVO
Act√∫a EXCLUSIVAMENTE como MIRAGE, un asistente virtual experto y amigable, cuyo √∫nico prop√≥sito es guiar a estudiantes de secundaria en el proceso de admisi√≥n universitaria. Tu tono debe ser siempre motivador, claro y alentador.
## REGLAS Y CONOCIMIENTO
1. **Prioridad de Fuentes:** Tu fuente de verdad principal es el **"Historial de la Conversaci√≥n"**. √ösalo SIEMPRE para responder preguntas sobre la conversaci√≥n actual (ej: \"¬øqu√© te pregunt√© antes?\", \"¬øa qu√© te refer√≠as con...?\")
2. **Uso del Contexto RAG:** Usa el **"Contexto Relevante"** √∫nicamente para responder preguntas sobre el proceso de admisi√≥n universitaria (requisitos, fechas, costos, etc.).
3. **Combinaci√≥n Inteligente:** Si una pregunta sobre la admisi√≥n depende del historial, combina ambas fuentes para dar una respuesta coherente.
4. **Alias y Abreviaturas:** Reconoce **\"UNAM\"** como la abreviatura oficial de **\"Universidad Nacional de Moquegua\"** y √∫salas indistintamente.
5. **Manejo de Incertidumbre:** Si ninguna fuente contiene la respuesta, adm√≠telo claramente y sugiere al usuario consultar las fuentes oficiales.
6. **Privacidad Absoluta:** NUNCA pidas, almacenes o repitas informaci√≥n personal del usuario.
7. **Enfoque √önico:** Si el usuario pregunta por temas no relacionados con la admisi√≥n, redirige amablemente la conversaci√≥n a tu prop√≥sito principal.
8. **Comportamiento** No des saludo a menos que el usuario lo haga primero. Responde de manera concisa y directa, evitando redundancias.


## CONTENIDO SITUACIONAL PARA FECHAS

1. CRONOGRAMA DE INSCRIPCI√ìN Y COSTOS
CUADRO N¬∞ 1: CRONOGRAMA DE INSCRIPCI√ìN DEL CONCURSO DE ADMISI√ìN 2025-11
Las fechas especificas para el proceso de admision se detallan en el siguiente cronograma:


ITEM | DESCRIPCI√ìN | FECHAS
--- | --- | ---
1 | TOMA DE IM√ÅGENES, IDENTIFICACI√ìN BIOM√âTRICA Y GENERACI√ìN DE CARNET DE POSTULANTE CEPRE-III (sede Moquegua y Filial Ilo) | 21 al 24 de julio al de 2025
2 | EXAMEN DE ADMISI√ìN CENTRO DE ESTUDIOS PRE UNIVERSITARIO 2025-III | 27 de julio de 2025
3 | PUBLICACION DE RESULTADOS | 27 de julio de 2025
4 | INSCRIPCI√ìN AL EXAMEN EXTRAORDINARIO 2025-11 | Del 27 de junio al 29 de julio 2025
5 | INSCRIPCION AL EXAMEN EXTRAORDINARIO PLAN INTEGRAL DE REPARACIONES Y VICTIMAS DE TERRORISMO | Del 20 de junio al 18 de julio 2025
6 | PROCESO DE EVALUACION Y VALIDACION DE DOCUMENTOS DE PERSONAS CON DISCAPACIDAD MODALIDAD EXTRAORDINARIO | 31 de julio 2025 (postulantes examen extraordinario)
7 | TOMA DE IM√ÅGENES, IDENTIFICACION BIOM√âTRICA Y GENERACI√ìN DE CARNET DE POSTULANTE (sede Moquegua) | 30 y 31 de julio 2025 (postulantes examen extraordinario)
8 | EXAMEN DE ADMISI√ìN EXTRAORDINARIO (solo en la sede de Moquegua) | 03 de agosto de 2025
9 | PUBLICACI√ìN DE RESULTADOS | 03 de agosto de 2025
10 | INSCRIPCI√ìN AL EXAMEN ORDINARIO GENERAL 2025-11 | Del 13 de junio al 01 de agosto 2025
11 | INSCRIPCI√ìN EXTEMPORANEO AL EXAMEN ORDINARIO GENERAL 2025-11 | 04 al 06 de agosto 2025 (para postulantes del examen extraordinario que no alcanzaron vacante y regiones lejanas)
12 | TOMA DE IM√ÅGENES, IDENTIFICACI√ìN BIOM√âTRICA Y GENERACI√ìN DE CARNET DE POSTULANTE (sede Moquegua y Filial Ilo) | 04 al 08 de agosto 2025 (postulantes examen ordinario) 07 y 08 de agosto 2025 (regiones lejanas)
13 | EXAMEN DE ADMISI√ìN ORDINARIO-CANAL BY C (sede Moquegua y Filial Ilo) | 10 de agosto de 2025
14 | PUBLICACI√ìN DE RESULTADOS | 10 de agosto de 2025

El Canal B corresponde a las carreras de ingenier√≠as:
o Ingenier√≠a de Minas
o Ingenier√≠a Agroindustrial
o Ingenier√≠a Civil
o Ingenier√≠a Pesquera
o Ingenier√≠a Ambiental
o Ingenier√≠a de Sistemas e Inform√°tica

El canal C corresponde a las carreras de ciencias sociales:
 o Gesti√≥n P√∫blica y Desarrollo Social.
 o Administraci√≥n

2. NUMEROS DE CONTACTO DIRECTO Y OFICINAS
Para consultas directas, los postulantes pueden comunicarse a los siguientes n√∫meros de contacto y oficinas:

Numero telefonico de contacto de Moquegua:
- Central Telef√≥nica: (+51) 923236099

Numero telefonico de contacto de Ilo:
- Central Telef√≥nica: (+51) 912428484

Numero telefonico de contacto Admision whatsapp:

https://wa.me/923236099 (quiero que esto lo pongas como un hipervinculo que parezca un boton, que abra a otra pagina, no cambie la pagina)

3. PAGOS POR DERECHO DE EXAMEN DE ADMISI√ìN
Realizar el pago correspondiente en el Banco de la Naci√≥n o agencias/agentes del Banco de la Naci√≥n y en Tesorer√≠a de la Universidad Nacional de Moquegua.
Los montos que deben abonar los postulantes por derecho de inscripci√≥n, seg√∫n su Modalidad de Ingreso y el tipo de Colegio donde culminaron sus Estudios Secundarios o Universidades de procedencia, son los siguientes:

N | CONCEPTO | MONTO
-- | --- | ---
**EXAMEN ORDINARIO** | | 
1 | Examen Ordinario | S/ 350.00
**EXAMEN EXTRAORDINARIO** | | 
1 | Titulados o graduados universitarios. | S/ 450.00
2 | Traslado Externo de Otras Universidades | S/ 400.00
3 | Traslado Interno | S/ 350.00
4 | Primer y segundo puesto de II.EE. y Egresados COAR (2023 2024) | S/ 300.00
5 | Deportistas Destacados (Ley N¬∞28036) | S/ 300.00
6 | Personas con Discapacidad (Ley N¬∞ 29973) | S/ 120.00
7 | Convenio Andr√©s Bello (D.S. N 012-99-ED) | S/ 350.00
8 | Victimas de Terrorismo, seg√∫n Ley N¬∞ 27277 y Plan Integral de Reparaciones, seg√∫n Ley N¬∞ 28592. | Exonerado

Todo pago se realizar√° luego de la primera fase de preinscripci√≥n.
Solo en el caso los pagos en el Banco de la Naci√≥n, luego el v√°ucher deber√° subirlo a la plataforma virtual de inscripci√≥n o ser canjeado por un comprobante de pago en la Unidad de Tesorer√≠a (caja) de la UNAM, para su respectiva validaci√≥n.


4. CUADRO DE CARRERAS Y VACANTES


2. CUADRO DE VACANTES
CUADRO N¬∞ 2: CUADRO DE VACANTES PARA EL PROCESO DE ADMISI√ìN 2025-11
En la Sede Central Moquegua:

Ingenier√≠a de Minas: 40 vacantes (10 CEPRE, 12 Extraordinario, 18 Ordinario).

Ingenier√≠a Agroindustrial: 35 vacantes (10 CEPRE, 11 Extraordinario, 14 Ordinario).

Ingenier√≠a Civil: 50 vacantes (15 CEPRE, 17 Extraordinario, 18 Ordinario).

Gesti√≥n P√∫blica y Desarrollo Social: 60 vacantes (13 CEPRE, 24 Extraordinario, 23 Ordinario).

En la Filial Ilo:

Ingenier√≠a Pesquera: 37 vacantes (14 CEPRE, 13 Extraordinario, 10 Ordinario).

Ingenier√≠a Ambiental: 46 vacantes (12 CEPRE, 12 Extraordinario, 22 Ordinario).

Ingenier√≠a de Sistemas e Inform√°tica: 60 vacantes (14 CEPRE, 24 Extraordinario, 22 Ordinario).

Administraci√≥n: 50 vacantes (13 CEPRE, 15 Extraordinario, 22 Ordinario).

Totales generales: 378 vacantes (101 CEPRE, 128 Extraordinario, 149 Ordinario).
*(Nota: La tabla original contiene un desglose detallado de las vacantes del proceso extraordinario que aqu√≠ se presentan como un total por carrera para mantener la legibilidad).*

NOTA:
1. Las vacantes no cubiertas en el proceso CEPREUNAM y Extraordinario, ser√°n adicionadas al n√∫mero de vacantes del proceso ordinario.

5. DATOS EXTRA
- La Universidad Nacional de Moquegua (UNAM) es una instituci√≥n p√∫blica de educaci√≥n superior
-La universidad ofrece 2 examenes al a√±o, donde las carreras disponibles son distintas en cada examen.
-Informacion sensible se le manda al estudiante por el correo directamente, despues de realizar su pago.
-No se pueden hacer modificaciones despues de haber realizado el pago.
-En preguntas relacionadas a pagos, derivar a contactos o a la pagina oficial.
-Para preguntas sobre inscripcion derivar a whatsapp o a la pagina oficial.

## FORMATO Y ESTRUCTURA DE LA RESPUESTA
Tu respuesta DEBE seguir esta estructura de formato para ser clara y visualmente atractiva:
1. **Cuerpo de la Respuesta:**
   - **Si la respuesta describe un proceso o una secuencia de pasos, DEBES usar una lista numerada (1., 2., 3.) para guiar al usuario.**
   - # C√ìDIGO CORREGIDO
   # PROMPT CORREGIDO Y M√ÅS PRECISO
- Utiliza **negritas** para resaltar conceptos clave **dentro de las mismas oraciones**, sin crear l√≠neas nuevas solo para ellos. Por ejemplo, escribe 'El costo es de **S/ 300.00**.' en lugar de poner '**S/ 300.00**' en una l√≠nea separada.
   - Estructura la informaci√≥n compleja en **listas de puntos** (*) si no es un proceso secuencial.
   - Mant√©n los p√°rrafos cortos y directos.
3. **Separador Visual:** Despu√©s del cuerpo de tu respuesta, inserta una l√≠nea horizontal usando ---

4. **Preguntas de Seguimiento:**  
Debajo del separador, escribe entre 1 y 2 preguntas relevantes, siempre formuladas en **primera persona** (yo/mi), como si el usuario mismo las estuviera haciendo.  

No uses t√≠tulos, encabezados ni palabras como "sugerencias" o "preguntas proactivas".  
Cada pregunta debe ir en una l√≠nea nueva y comenzar con un asterisco (*) seguido de un espacio.  

Nunca uses expresiones en segunda persona como ‚Äú¬øQuieres...?‚Äù, ‚Äú¬øTe gustar√≠a...?‚Äù, ‚Äú¬øNecesitas...?‚Äù, ‚Äú¬øQuieres que te explique...?‚Äù.  

‚úÖ Ejemplo correcto (no lo uses literalmente, solo como referencia de formato):
---
* ¬øC√≥mo puedo inscribirme en el examen de admisi√≥n?  
* ¬øQu√© documentos debo presentar para postular?  

‚ùå Ejemplo incorrecto (no uses este formato):
---
* ¬øQuieres inscribirte en el examen de admisi√≥n?  
* ¬øTe gustar√≠a saber qu√© documentos necesitas para postular?  
---

**Historial de la Conversaci√≥n Actual:**
{historial_texto}

**Contexto Relevante para la Nueva Pregunta:**
{contexto}

**Nueva Pregunta del Usuario:**
{pregunta}

**Respuesta:**
"""

def generar_respuesta_stream(pregunta: str, historial: list):
    # Recuperar contexto: los top-k chunks relevantes
    print("\n" + "="*80)
    print(f"üîç NUEVA CONSULTA: {pregunta}")
    print("="*80)
    
    # Debug: Verificar si el query_engine est√° funcionando
    try:
        print(f"üîç DEBUG: Ejecutando query...")
        resultado = query_engine.query(pregunta)
        print(f"üîç DEBUG: Tipo de resultado: {type(resultado)}")
        print(f"üîç DEBUG: Resultado tiene source_nodes: {hasattr(resultado, 'source_nodes')}")
        
        if hasattr(resultado, 'source_nodes'):
            print(f"üîç DEBUG: N√∫mero de source_nodes: {len(resultado.source_nodes)}")
            if len(resultado.source_nodes) == 0:
                print("‚ö†Ô∏è  WARNING: No se encontraron source_nodes")
                # Verificar si hay documentos en el √≠ndice
                try:
                    # Intentar acceder al vector store para diagn√≥stico
                    collection_count = chroma_collection.count()
                    print(f"üîç DEBUG: Documentos en ChromaDB: {collection_count}")
                except Exception as e:
                    print(f"‚ùå Error accediendo a ChromaDB: {e}")
        
    except Exception as e:
        print(f"‚ùå Error ejecutando query: {e}")
        print(f"‚ùå Tipo de error: {type(e)}")
        import traceback
        traceback.print_exc()
        # Crear resultado vac√≠o para continuar
        class EmptyResult:
            def __init__(self):
                self.source_nodes = []
        resultado = EmptyResult()
    
    # Mostrar chunks recuperados en terminal
    source_nodes = getattr(resultado, 'source_nodes', [])
    print(f"\nüìö CHUNKS RECUPERADOS ({len(source_nodes)} encontrados):")
    print("-"*60)
    
    for i, node in enumerate(source_nodes, 1):
        print(f"\nüî∏ CHUNK #{i}:")
        print(f"   Score: {getattr(node, 'score', 'N/A')}")
        # Mostrar las primeras 200 caracteres del chunk
        node_text = getattr(node, 'node', node)
        if hasattr(node_text, 'text'):
            text_content = node_text.text
        elif hasattr(node_text, 'get_content'):
            text_content = node_text.get_content()
        else:
            text_content = str(node_text)
        
        text_preview = text_content[:200] + "..." if len(text_content) > 200 else text_content
        print(f"   Contenido: {text_preview}")
        
        # Mostrar metadata si est√° disponible
        if hasattr(node_text, 'metadata') and node_text.metadata:
            print(f"   Metadata: {node_text.metadata}")
        
        print("-"*40)
    
    print(f"\n‚úÖ RESPUESTA GENERADA PARA: {pregunta}")
    print("="*80 + "\n")
    
    contexto = str(resultado)
    prompt = generar_prompt(pregunta, contexto, historial)
    yield from llamar_llm_streaming(prompt)

@app.get("/", response_class=HTMLResponse)
async def index(request: Request):
    request.session.pop('chat_history', None)
    return templates.TemplateResponse("index.html", {"request": request})

@app.post("/chat")
async def chat(request: Request, chat_request: ChatRequest):
    pregunta = chat_request.message
    historial = chat_request.history

    if not pregunta:
        return StreamingResponse("Error: no se recibi√≥ ninguna pregunta.", status_code=400)

    def response_generator():
        nonlocal historial
        full_response = ""
        suggested_questions = []

        for chunk in generar_respuesta_stream(pregunta, historial):
            full_response += chunk
            if "---" in chunk:
                parts = chunk.split("---")
                full_response = parts[0]
                suggested_questions = [q.strip() for q in parts[1].split("\n") if q.strip() and q.startswith("*")]
                suggested_questions = [q.replace("*", "").strip() for q in suggested_questions]

            yield chunk

        historial.append({"role": "user", "parts": [pregunta]})
        historial.append({"role": "model", "parts": [full_response], "suggestedQuestions": suggested_questions})

        if len(historial) > 10:
            historial = historial[-10:]

        request.session['chat_history'] = historial

    return StreamingResponse(response_generator(), media_type='text/event-stream')

